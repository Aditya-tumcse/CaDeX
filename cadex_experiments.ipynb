{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert D-FAUST dataset into .ply file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/usr/stud/srinivaa/code/CaDeX/resource/data/Humans/D-FAUST/50002_hips/pcl_seq/00000003.npz\"\n",
    "data = np.load(file_path)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(data['points'])\n",
    "o3d.io.write_point_cloud(\"data_3.ply\", pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the attributes of pcl_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points\n",
      "loc\n",
      "scale\n"
     ]
    }
   ],
   "source": [
    "for i in data.files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the attributes of points_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points\n",
      "occupancies\n",
      "loc\n",
      "scale\n"
     ]
    }
   ],
   "source": [
    "points_seq = np.load(\"/usr/stud/srinivaa/code/CaDeX/resource/data/Humans/D-FAUST/50002_chicken_wings/points_seq/00000000.npz\")\n",
    "for i in points_seq.files:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of total dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(\"/usr/stud/srinivaa/code/CaDeX/resource/data/Humans/D-FAUST\"))\n",
    "total_file_size = 0\n",
    "\n",
    "for i in range(len(dirs)): \n",
    "    if(dirs[i] != '50004_chicken_wings' and dirs[i] != '50020_hips' and dirs[i] != '50025_shake_arms' and dirs[i] != '50020_running_on_spot' and dirs[i] != '50007_light_hopping_loose'):\n",
    "        path_i,dirs_i,files_i = next(os.walk(os.path.join(path,dirs[i],'points_seq')))\n",
    "        total_file_size += len(files_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39920"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = next(os.walk(\"/usr/stud/srinivaa/code/CaDeX/resource/data/Humans/D-FAUST\"))\n",
    "total_file_size = 0\n",
    "\n",
    "for i in range(len(dirs)): \n",
    "    if(dirs[i] != '50002_light_hopping_loose' and dirs[i] != '50004_punching' and dirs[i] != '50007_shake_shoulders' and dirs[i] != '50009_chicken_wings' and dirs[i] != '50020_chicken_wings' and dirs[i] != '50022_light_hopping_loose' and dirs[i] != '50025_light_hopping_loose' and dirs[i] != '50026_shake_arms' and dirs[i] != '50027_shake_shoulders' and dirs[i] != '50004_chicken_wings' and dirs[i] != '50020_hips' and dirs[i] != '50025_shake_arms' and dirs[i] != '50020_running_on_spot' and dirs[i] != '50007_light_hopping_loose'):\n",
    "        path_i,dirs_i,files_i = next(os.walk(os.path.join(path,dirs[i],'points_seq')))\n",
    "        total_file_size += len(files_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37867"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_file_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset of CaDeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset.oflow_dataset as oflow_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    \"\"\"Returns transform objects.\n",
    "\n",
    "    Args:\n",
    "        cfg (yaml config): yaml config object\n",
    "    \"\"\"\n",
    "    n_pcl = 100\n",
    "    n_pt = 512\n",
    "    n_pt_eval = 10000\n",
    "\n",
    "    transf_pt = oflow_dataset.SubsamplePoints(n_pt)\n",
    "    transf_pt_val = oflow_dataset.SubsamplePointsSeq(n_pt_eval, random=False)\n",
    "    transf_pcl_val = oflow_dataset.SubsamplePointcloudSeq(n_pt_eval, random=False)\n",
    "    transf_pcl = oflow_dataset.SubsamplePointcloudSeq(n_pcl, connected_samples=True)\n",
    "\n",
    "    return transf_pt, transf_pt_val, transf_pcl, transf_pcl_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_fields(mode):\n",
    "    \"\"\"Returns data fields.\n",
    "\n",
    "    Args:\n",
    "        mode (str): mode (train|val|test)\n",
    "        cfg (yaml config): yaml config object\n",
    "    \"\"\"\n",
    "    fields = {}\n",
    "    seq_len_train = 17\n",
    "   \n",
    "    seq_len_val = seq_len_train\n",
    "    p_folder = \"points_seq\" # points_seq: contains information regarding the points and their corresponding occupancy values\n",
    "    pcl_folder = \"pcl_seq\" #pcl_seq : contains information regarding the points, scale and loc\n",
    "    mesh_folder = \"mesh_seq\" #mesh_seq: non-existent. Utilize this to have a file containing points and faces for each model.\n",
    "    generate_interpolate = False #False\n",
    "    unpackbits = True # True\n",
    "    \n",
    "    training_all = False\n",
    "    \n",
    "    n_training_frames = 8\n",
    "\n",
    "    # Transformation\n",
    "    transf_pt, transf_pt_val, transf_pcl, transf_pcl_val = get_transforms()\n",
    "\n",
    "    # Fields\n",
    "    pts_iou_field = oflow_dataset.PointsSubseqField\n",
    "    pts_corr_field = oflow_dataset.PointCloudSubseqField\n",
    "\n",
    "    # MeshSubseqField can be used to load mesh fields\n",
    "\n",
    "  \n",
    "    not_choose_last = False\n",
    "    training_multi_files = False\n",
    "    \n",
    "    loss_recon = \"true\"\n",
    "    loss_corr = \"true\"\n",
    "\n",
    "    if mode == \"train\":\n",
    "        if loss_recon:\n",
    "            if training_all:\n",
    "                fields[\"points\"] = pts_iou_field(\n",
    "                    p_folder,\n",
    "                    transform=transf_pt,\n",
    "                    all_steps=True,\n",
    "                    seq_len=seq_len_train,\n",
    "                    unpackbits=unpackbits,\n",
    "                    use_multi_files=training_multi_files,\n",
    "                )\n",
    "            else:\n",
    "                fields[\"points\"] = pts_iou_field(\n",
    "                    p_folder,\n",
    "                    sample_nframes=n_training_frames,\n",
    "                    transform=transf_pt,\n",
    "                    seq_len=seq_len_train,\n",
    "                    fixed_time_step=0,\n",
    "                    unpackbits=unpackbits,\n",
    "                    use_multi_files=training_multi_files,\n",
    "                )\n",
    "            fields[\"points_t\"] = pts_iou_field(\n",
    "                p_folder,\n",
    "                transform=transf_pt,\n",
    "                seq_len=seq_len_train,\n",
    "                unpackbits=unpackbits,\n",
    "                not_choose_last=not_choose_last,\n",
    "                use_multi_files=training_multi_files,\n",
    "            )\n",
    "\n",
    "\n",
    "            fields[\"mesh\"] = oflow_dataset.MeshField(\n",
    "            mesh_folder, seq_len=seq_len_val)\n",
    "\n",
    "    # only training can be boost by multi-files\n",
    "    # modify here, if not train, val should also load the same as the test\n",
    "    else:\n",
    "        fields[\"points\"] = pts_iou_field(\n",
    "            p_folder,\n",
    "            transform=transf_pt_val,\n",
    "            all_steps=True,\n",
    "            seq_len=seq_len_val,\n",
    "            unpackbits=unpackbits,\n",
    "        )\n",
    "        fields[\n",
    "            \"points_mesh\"\n",
    "        ] = pts_corr_field(  # ? this if for correspondence? Checked, this is for chamfer distance, make sure that because here we use tranforms, teh pts in config file must be 100000\n",
    "            pcl_folder, transform=transf_pcl_val, seq_len=seq_len_val\n",
    "        )\n",
    "    # Connectivity Loss:\n",
    "    if loss_corr:\n",
    "        # fields[\"pointcloud\"] = pts_corr_field(\n",
    "        #     pcl_folder,\n",
    "        #     transform=transf_pcl,\n",
    "        #     seq_len=seq_len_train,\n",
    "        #     use_multi_files=training_multi_files,\n",
    "        # )\n",
    "        fields[\"pointcloud\"] = oflow_dataset.MeshField(\n",
    "            mesh_folder, seq_len=seq_len_val)\n",
    "    if mode == \"test\" and generate_interpolate:\n",
    "        fields[\"mesh\"] = oflow_dataset.MeshSubseqField(\n",
    "            mesh_folder, seq_len=seq_len_val, only_end_points=True\n",
    "        )\n",
    "    fields[\"oflow_idx\"] = oflow_dataset.IndexField()\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = get_data_fields(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"/usr/data/cvpr_shared/marvin/Data/CaDeX/data/Humans\"\n",
    "categories = [\"D-FAUST\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = oflow_dataset.HumansDataset(\n",
    "        dataset_folder,\n",
    "        fields,\n",
    "        split=\"train\",\n",
    "        categories=categories,\n",
    "        length_sequence=17,\n",
    "        n_files_per_sequence=-1,\n",
    "        offset_sequence=15,\n",
    "        ex_folder_name=\"mesh_seq\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'arrray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1545676/425756422.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mesh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/usr/data/cvpr_shared/marvin/Data/CaDeX/data/Humans/D-FAUST/50002_chicken_wings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/new_CaDeX/CaDeX/dataset/oflow_dataset/fields.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model_path, idx, c_idx, start_idx, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m         data = {\n\u001b[1;32m    715\u001b[0m             \u001b[0;34m\"vertices\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_vertices_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0;34m\"triangles\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_face_seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         }\n",
      "\u001b[0;32m~/anaconda3/envs/cadex/lib/python3.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0;32m--> 314\u001b[0;31m                                  \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arrray'"
     ]
    }
   ],
   "source": [
    "dataset.fields['mesh'].load(\"/usr/data/cvpr_shared/marvin/Data/CaDeX/data/Humans/D-FAUST/50002_chicken_wings\",0,0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 2022-09-08 20:44:47,528 - subseq_dataset - Error occured when loading field mesh of model 50002_one_leg_loose\n"
     ]
    }
   ],
   "source": [
    "dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cadex_exp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f69e42e045f89194479371b8eea8a8fbbb97f0f3791ce778bd37be11cbc69304"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
